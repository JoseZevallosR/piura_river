count=count+1
class_matrix[i,]=c(breaks[i],breaks[i+1],count)
legenda=c(legenda,paste(as.character(round(breaks[i],2)),as.character(round(breaks[i+1],2)),sep = '-'))
}
list(matt=class_matrix,legends=legenda)
}
map = raster(dir)
c(matt,legenda):=reclass_raster(breaks = breaks_df(na.omit(values(map)),n))
map = reclassify(map,matt,include.lowest=TRUE)
map.p=rasterToPoints(map)
df <- data.frame(map.p)
colnames(df) = c("Longitude", "Latitude", "MAP")
list(df=df,legenda=legenda)
}
plot_map=function(df.map,legenda,titulo,shapefile_df){
#Mypal=gray.colors(length(legenda))
Mypal=topo.colors(length(legenda))
#number of intervals
ggplot(data=df.map, aes(y=Latitude, x=Longitude)) +
geom_raster(aes(fill=factor(MAP))) +scale_x_continuous(limits = c(-82.0,-67.5),breaks= scales::pretty_breaks(n=4))+
theme(axis.text.x = element_text(size=10),legend.key.height = unit(0.5, 'cm'),legend.text = element_text(size=10),legend.position="left",plot.title = element_text(hjust = 0.5))+ggtitle(titulo)+
scale_fill_manual(values =  Mypal,labels=legenda,name=NULL)+
coord_equal()+geom_path(data = shapefile_df,aes(x = long, y = lat, group = group),color = 'black', size = .5)
}
graficoVS=function(y,obs,sim){
df=data.frame(y,obs,sim)
names(df)=c('y','obs','sim')
df=mutate(df,Location=factor(case_when(y>-19   & y<=-12.7 ~'Costa sur',
y>-12.7 & y<=-6.4  ~ 'Costa central',
y>-6.4  & y<=0     ~'Costa norte')))
#ggplot(df, aes(x = obs, y = sim,colour=Location))
img=ggplot(df, aes(x = obs, y = sim))+geom_point(size=2, shape=20)+geom_abline(intercept = 0)
#leyenda=g_legend(img)
img=img+theme(legend.position="none")+theme(axis.title.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.ticks.y=element_blank())
leyenda=0
list(img,leyenda)
}
plot_comparison=function(gauge_stat,simulated_stats,file_save_name,language='Spanish'){
if (language == 'Spanish'){
c(img11,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean24,simulated_stats$mean24)
img11=img11+labs(title='Promedio (mm)')+theme(plot.title = element_text(hjust = 0.5,size=10))
img12=graficoVS(gauge_stats$y,gauge_stats$var24,simulated_stats$var24)[[1]]
img12=img12+labs(title='Varianza')+theme(plot.title = element_text(hjust = 0.5,size=10))
img13=graficoVS(gauge_stats$y,gauge_stats$autocov24,simulated_stats$autocov24)[[1]]
img13=img13+labs(title='Lag-1 Autocovarianza')+theme(plot.title = element_text(hjust = 0.5,size=10))
img14=graficoVS(gauge_stats$y,gauge_stats$dryperiod24,simulated_stats$dryperiod24)[[1]]
img14=img14+labs(title='Probabilidad de 0 lluvia')+theme(plot.title = element_text(hjust = 0.5,size=10))
c(img21,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean3,simulated_stats$mean3)
img22=graficoVS(gauge_stats$y,gauge_stats$var3,simulated_stats$var3)[[1]]
img23=graficoVS(gauge_stats$y,gauge_stats$autocov3,simulated_stats$autocov3)[[1]]
img24=graficoVS(gauge_stats$y,gauge_stats$dryperiod3,simulated_stats$dryperiod3)[[1]]
c(img31,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean6,simulated_stats$mean6)
img32=graficoVS(gauge_stats$y,gauge_stats$var6,simulated_stats$var6)[[1]]
img33=graficoVS(gauge_stats$y,gauge_stats$autocov6,simulated_stats$autocov6)[[1]]
img34=graficoVS(gauge_stats$y,gauge_stats$dryperiod6,simulated_stats$dryperiod6)[[1]]
c(img41,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean12,simulated_stats$mean12)
img42=graficoVS(gauge_stats$y,gauge_stats$var12,simulated_stats$var12)[[1]]
img43=graficoVS(gauge_stats$y,gauge_stats$autocov12,simulated_stats$autocov12)[[1]]
img44=graficoVS(gauge_stats$y,gauge_stats$dryperiod12,simulated_stats$dryperiod12)[[1]]
bottom <- textGrob("Precipitaci?n diaria", gp = gpar(fontsize = 9))
left <- textGrob('CV Simulado 24-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
p1=arrangeGrob(img11,img12,img13,img14,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulado 3-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM sesgo corregido", gp = gpar(fontsize = 10))
p2=arrangeGrob(img21,img22,img23,img24,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulado 6-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM sesgo corregido", gp = gpar(fontsize = 10))
p3=arrangeGrob(img31,img32,img33,img34,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulado 12-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM sesgo corregido", gp = gpar(fontsize = 10))
p4=arrangeGrob(img41,img42,img43,img44,nrow = 1,ncol = 4,bottom = bottom,left = left)
}else{
c(img11,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean24,simulated_stats$mean24)
img11=img11+labs(title='Mean Rainfall (mm)')+theme(plot.title = element_text(hjust = 0.5,size=10))
img12=graficoVS(gauge_stats$y,gauge_stats$var24,simulated_stats$var24)[[1]]
img12=img12+labs(title='Variance')+theme(plot.title = element_text(hjust = 0.5,size=10))
img13=graficoVS(gauge_stats$y,gauge_stats$autocov24,simulated_stats$autocov24)[[1]]
img13=img13+labs(title='Lag-1 Autocovariance')+theme(plot.title = element_text(hjust = 0.5,size=10))
img14=graficoVS(gauge_stats$y,gauge_stats$dryperiod24,simulated_stats$dryperiod24)[[1]]
img14=img14+labs(title='Probability of 0 Rain')+theme(plot.title = element_text(hjust = 0.5,size=10))
c(img21,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean3,simulated_stats$mean3)
img22=graficoVS(gauge_stats$y,gauge_stats$var3,simulated_stats$var3)[[1]]
img23=graficoVS(gauge_stats$y,gauge_stats$autocov3,simulated_stats$autocov3)[[1]]
img24=graficoVS(gauge_stats$y,gauge_stats$dryperiod3,simulated_stats$dryperiod3)[[1]]
c(img31,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean6,simulated_stats$mean6)
img32=graficoVS(gauge_stats$y,gauge_stats$var6,simulated_stats$var6)[[1]]
img33=graficoVS(gauge_stats$y,gauge_stats$autocov6,simulated_stats$autocov6)[[1]]
img34=graficoVS(gauge_stats$y,gauge_stats$dryperiod6,simulated_stats$dryperiod6)[[1]]
c(img41,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean12,simulated_stats$mean12)
img42=graficoVS(gauge_stats$y,gauge_stats$var12,simulated_stats$var12)[[1]]
img43=graficoVS(gauge_stats$y,gauge_stats$autocov12,simulated_stats$autocov12)[[1]]
img44=graficoVS(gauge_stats$y,gauge_stats$dryperiod12,simulated_stats$dryperiod12)[[1]]
bottom <- textGrob("Daily rain gauge", gp = gpar(fontsize = 9))
left <- textGrob('CV Simulated 24-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
p1=arrangeGrob(img11,img12,img13,img14,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulated 3-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM bias corrected", gp = gpar(fontsize = 10))
p2=arrangeGrob(img21,img22,img23,img24,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulated 6-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM bias corrected", gp = gpar(fontsize = 10))
p3=arrangeGrob(img31,img32,img33,img34,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulated 12-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM bias corrected", gp = gpar(fontsize = 10))
p4=arrangeGrob(img41,img42,img43,img44,nrow = 1,ncol = 4,bottom = bottom,left = left)
}
figure=grid.arrange(p1,p2,p3,p4,nrow=4)
ggsave(file_save_name,figure,dpi=1200,units = 'cm',width =20 ,height =25 )
figure
}
maps_plot=function(file1,file2,file3,file4,file5,file6,intervals,file_save_name){
a=expression(alpha)
l=expression(paste(lambda,'(1/hr)'))
v=expression(paste(upsilon,'(hr)'))
k=expression(kappa)
phi=expression(phi)
u=expression(paste(mu,'(mm/hr)'))
c(df.map,legenda):=raster_to_df(file1,intervals)
mapa1=plot_map(df.map,legenda,titulo = a)
c(df.map,legenda):=raster_to_df(file2,intervals)
mapa2=plot_map(df.map,legenda,titulo = l)
c(df.map,legenda):=raster_to_df(file3,intervals)
mapa3=plot_map(df.map,legenda,titulo = v)
c(df.map,legenda):=raster_to_df(file4,intervals)
mapa4=plot_map(df.map,legenda,titulo = k)
c(df.map,legenda):=raster_to_df(file5,intervals)
mapa5=plot_map(df.map,legenda,titulo = phi)
c(df.map,legenda):=raster_to_df(file6,intervals)
mapa6=plot_map(df.map,legenda,titulo = u)
figure1=grid.arrange(arrangeGrob(mapa1,mapa2,mapa3,mapa4,mapa5,mapa6,nrow = 3))
ggsave(file_save_name,figure1,dpi=1200,units = 'cm',width =20 ,height =25 )
}
plot_cdf=function(file,par,titule,language='English'){
obs=data.frame(obs=nonzero(read.csv(file,sep = ',')$Rainfall.mm))
sim=data.frame(sim=nonzero(precp_sim(as.numeric(par),dim(obs)[1],tscale = 3)))
x=c(obs$obs,sim$sim)
g=c(rep(1,length(obs$obs)),rep(2,length(sim$sim)))
df=data.frame(x,g=factor(g))
if (language=='Spanish'){
ggplot(df,aes(x,colour=g))+stat_ecdf(geom = "point")+stat_ecdf(geom = "point")+
labs(color="Legend",title = titule,x='Acumulado 3 horas (mm)',y='CDF')+theme(legend.margin=margin(t = 0, unit='cm'),legend.title=element_blank(),plot.title = element_text(hjust = 0.5),legend.position = c(0.8, 0.25))+
scale_color_manual(labels = c("Observado", "Simulado"), values = c("red", "blue"))
}else{
ggplot(df,aes(x,colour=g))+stat_ecdf(geom = "point")+stat_ecdf(geom = "point")+
labs(color="Legend",title = titule,x='Three hourly (mm)',y='CDF')+theme(legend.margin=margin(t = 0, unit='cm'),legend.title=element_blank(),plot.title = element_text(hjust = 0.5),legend.position = c(0.8, 0.25))+
scale_color_manual(labels = c("Observed", "Synthetic"), values = c("red", "blue"))
}
}
opt='TRMM'
if (opt=='TRMM'){
#Mixed stats from gauge stations and corrected TRMM
gauge_stats=read.csv('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/data/feb_gauge_stat.csv')
#gauge_stats=kickOutliers(gauge_stats)
gauge_stats=filter_Neigbors(gauge_stats)
c(nrow,ncol) := dim(gauge_stats)
#Lmin=matrix(c(0.1,0.001,0.001,0.001,0.0854,1),nrow = 6,ncol = nrow)
#Lmax=matrix(c(4,0.1,0.1,0.1,0.1,20),nrow=6,ncol=nrow)
maps=run(rain_stats=gauge_stats,path="D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_parameters/",iterations=5,FILE_NAME='parameters_feb.csv')
}else if(opt =='GPM'){
#Mixed stats from gauge stations and corrected TRMM
gauge_stats=read.csv('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization
/data/gauge_stats.csv')
gauge_stats=kickOutliers(gauge_stats)
gauge_stats=filter_Neigbors(gauge_stats)
dim(gauge_stats)
maps=run(rain_stats=gauge_stats,path="D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization
/output/CV_parameters/",iterations=20)
}
source('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/src/InterpolationFunctions.R')
library(raster)
grd=readRDS('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/data/grilla.rds')
path_to_file='D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_parameters/parameters_feb.csv'
mapas_mes(path_to_file = path_to_file,grd,month = 'feb')
source('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/src/plotHelpers.R')
Peru <- shapefile("d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/data/Departamento_INEI_2017.shp")
# Next the shapefile has to be converted to a dataframe for use in ggplot2
shapefile_df <- fortify(Peru)
a=expression(alpha)
l=expression(paste(lambda,'(1/hr)'))
v=expression(paste(upsilon,'(hr)'))
k=expression(kappa)
phi=expression(phi)
u=expression(paste(mu,'(mm/hr)'))
#feb
dir1='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_1_feb.tif'
dir2='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_2_feb.tif'
dir3='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_3_feb.tif'
dir4='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_4_feb.tif'
dir5='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_5_feb.tif'
dir6='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_6_feb.tif'
c(df.map,legenda):=raster_to_df(dir1,10)
mapa1=plot_map(df.map,legenda,titulo = a,shapefile_df)
c(df.map,legenda):=raster_to_df(dir2,10)
mapa2=plot_map(df.map,legenda,titulo = l,shapefile_df)
c(df.map,legenda):=raster_to_df(dir3,10)
mapa3=plot_map(df.map,legenda,titulo = v,shapefile_df)
c(df.map,legenda):=raster_to_df(dir4,10)
mapa4=plot_map(df.map,legenda,titulo = k,shapefile_df)
c(df.map,legenda):=raster_to_df(dir5,10)
mapa5=plot_map(df.map,legenda,titulo = phi,shapefile_df)
c(df.map,legenda):=raster_to_df(dir6,10)
mapa6=plot_map(df.map,legenda,titulo = u,shapefile_df)
figure1=grid.arrange(arrangeGrob(mapa1,mapa2,mapa3,mapa4,mapa5,mapa6,nrow = 3))
ggsave("D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/img/parameters_february.png",figure1,dpi=1200,units = 'cm',width =20 ,height =25 )
library(raster)
a=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_1_feb.tif')
v=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_3_feb.tif')
fi=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_5_feb.tif')
k=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_4_feb.tif')
l=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_2_feb.tif')
mu=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_6_feb.tif')
average_rain_cell_duration=v/a
average_number_cell_per_storn=1+k/fi
average_storm_duration=v/(fi*a)#
average_rainfall_deph_storm=mu*(v/a)*(1+k/fi)
writeRaster(average_rain_cell_duration,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rain_cell_duration.tif',overwrite=T)
writeRaster(average_storm_duration,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_storm_duration.tif',overwrite=T)
writeRaster(average_rainfall_deph_storm,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rainfall_deph_storm.tif',overwrite=T)
writeRaster(average_number_cell_per_storn,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_number_cell_per_storn.tif',overwrite=T)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_number_cell_per_storn.tif',6)
mapa1=plot_map(df.map,legenda,titulo = '(a) Average number \n of rain cell per storm',shapefile_df)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rain_cell_duration.tif',6)
mapa2=plot_map(df.map,legenda,titulo = '(b) Average duration \n of rain cell (hr)',shapefile_df)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_storm_duration.tif',6)
mapa3=plot_map(df.map,legenda,titulo = '(c) Average rainfall \n duration (hr)',shapefile_df)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rainfall_deph_storm.tif',6)
mapa4=plot_map(df.map,legenda,titulo = '(d) Average rain deph \n per storm (mm)',shapefile_df)
figure2=grid.arrange(arrangeGrob(mapa1,mapa2,mapa3,mapa4,nrow = 2))
ggsave("D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/img/storm_characteristics.png",figure2,dpi=1200,units = 'cm',width =20 ,height =20 )
1+2
5*9
1
1.2
TRUE
FALSE
True
TRUE
FALSE
1+1
1*2
1/9
3**2
3^2
5**3
"Hola mundo"
Hola mundo
3**2
3**2
9+9
3**2
9+9
3**2
9+9
3**2
9+9
x = 8
x+x
2*x
x**2
x**3
x = 8
x = 9
x
cuadrado = function(x){
return(x**2)
}
cuadrado = function(x){
# Esta funcion sirve para elevar numeros al cuadrado
return(x**2)
}
cuadrado(9)
3**2
cuadrado(8)
cuadrado(7)
Cuadrado(1)
potencia = function(x,n){
return(x**n)
}
potencia = function(x,n){
return(x**n)
}
return(x**n)
potencia(7,3)
potencia(8,5)
Potencia(1,1)
potencia(8,7)
install.packages("plotly")
library(plotly)
library(plotly)
library(plotly)
library(plotly)
library(plumber)
detach("package:plumber", unload = TRUE)
library(raster)
library(plotly)
USPersonalExpenditure <- data.frame("Categorie"=rownames(USPersonalExpenditure), USPersonalExpenditure)
x = 1
x
x <- 2
x
View(USPersonalExpenditure)
USPersonalExpenditure
USPersonalExpenditure[,'Categorie']
c(1,2,3)
c("a","b","c")
USPersonalExpenditure[,c('Categorie','X1940')]
data = USPersonalExpenditure[,c('Categorie', 'X1960')]
data
fig = plotly::plot_ly(data, labels = ~Categorie, values = ~X1960, type = 'pie')
fig = fig %>% layout(title = 'United States Personal Expenditures by Categories in 1960',
xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
fig
# Load the plotly library
library(plotly)
# Create sample data
data <- data.frame(
category = c("A", "B", "C", "D"),
values = c(23, 17, 35, 29)
)
# Create a bar chart
fig <- plot_ly(
data,
x = ~category,
y = ~values,
type = 'bar',
marker = list(color = 'rgba(58, 71, 80, 0.6)', line = list(color = 'rgba(58, 71, 80, 1.0)', width = 1.5))
)
# Add titles
fig <- fig %>%
layout(
title = "Sample Bar Chart",
xaxis = list(title = "Category"),
yaxis = list(title = "Values")
)
# Display the plot
fig
# Cargar librerías necesarias
library(dplyr)
library(agricolae)
library(car) # Para la verificación de suposiciones
# Crear el dataframe original con los valores medios y la desviación estándar para cada variable
data <- data.frame(
Intensidad_Pastoreo = c("G0", "G0.7", "G1.2", "G1.6"),
P_mean = c(0.86, 1.74, 1.14, 1.42),
P_sd = c(0.04, 0.08, 0.04, 0.12),
NO3_mean = c(0.07, 0.12, 0.10, 0.08),
NO3_sd = c(0.004, 0.006, 0.008, 0.01),
NH4_mean = c(1.26, 1.13, 1.22, 1.37),
NH4_sd = c(0.08, 0.06, 0.06, 0.11)
)
# Crear un dataframe vacío para almacenar los resultados
data_expanded <- data.frame()
# Iterar sobre cada fila del dataframe original y crear las repeticiones
for (i in 1:nrow(data)) {
# Para cada variable (P, NO3-N, NH4+-N), generar las tres repeticiones
temp <- data.frame(
Fecha = rep("2013", 9),  # Ajuste de fecha para el año del estudio
Intensidad_Pastoreo = rep(data$Intensidad_Pastoreo[i], 9),
Psuelo = rep(c("P", "NO3-N", "NH4+-N"), each = 3),
Valor = c(
data$P_mean[i] - data$P_sd[i], data$P_mean[i], data$P_mean[i] + data$P_sd[i],
data$NO3_mean[i] - data$NO3_sd[i], data$NO3_mean[i], data$NO3_mean[i] + data$NO3_sd[i],
data$NH4_mean[i] - data$NH4_sd[i], data$NH4_mean[i], data$NH4_mean[i] + data$NH4_sd[i]
)
)
# Añadir los datos temporales al dataframe expandido
data_expanded <- rbind(data_expanded, temp)
}
# Mostrar el dataframe expandido
print(data_expanded)
data_expanded$Fecha = NULL
# Ordenar el dataframe expandido por la columna "Variable"
data_expanded <- arrange(data_expanded, Psuelo)
# Reorganizar las columnas para que "Variable" sea la primera
data_expanded <- select(data_expanded, Psuelo, everything())
# Mostrar el dataframe resultante
print(data_expanded)
# Asegurarse de que los factores estén correctamente definidos
data_expanded$Intensidad_Pastoreo <- as.factor(data_expanded$Intensidad_Pastoreo)
data_expanded$Psuelo <- as.factor(data_expanded$Psuelo)
# Anova para DBCA
res.aov <- aov(Valor ~ Intensidad_Pastoreo + Psuelo, data = data_expanded)
summary(res.aov)
ss = 0
u = c(0.73,0.99667,0.82,095667)
for (k in 1:9){
for (t in 1:4){
ss = ss +(u[t]-0.876)**2
}
}
ss
u[t]
ss = 0
u = c(0.73,0.99667,0.82,0.95667)
for (k in 1:9){
for (t in 1:4){
ss = ss +(u[t]-0.876)**2
}
}
ss
# Cargar librerías necesarias
library(dplyr)
library(agricolae)
library(car) # Para la verificación de suposiciones
# Crear el dataframe original con los valores medios y la desviación estándar para cada variable
data <- data.frame(
Intensidad_Pastoreo = c("G0", "G0.7", "G1.2", "G1.6"),
P_mean = c(0.86, 1.74, 1.14, 1.42),
P_sd = c(0.04, 0.08, 0.04, 0.12),
NO3_mean = c(0.07, 0.12, 0.10, 0.08),
NO3_sd = c(0.004, 0.006, 0.008, 0.01),
NH4_mean = c(1.26, 1.13, 1.22, 1.37),
NH4_sd = c(0.08, 0.06, 0.06, 0.11)
)
# Crear un dataframe vacío para almacenar los resultados
data_expanded <- data.frame()
# Iterar sobre cada fila del dataframe original y crear las repeticiones
for (i in 1:nrow(data)) {
# Para cada variable (P, NO3-N, NH4+-N), generar las tres repeticiones
temp <- data.frame(
Fecha = rep("2013", 9),  # Ajuste de fecha para el año del estudio
Intensidad_Pastoreo = rep(data$Intensidad_Pastoreo[i], 9),
Psuelo = rep(c("P", "NO3-N", "NH4+-N"), each = 3),
Valor = c(
data$P_mean[i] - data$P_sd[i], data$P_mean[i], data$P_mean[i] + data$P_sd[i],
data$NO3_mean[i] - data$NO3_sd[i], data$NO3_mean[i], data$NO3_mean[i] + data$NO3_sd[i],
data$NH4_mean[i] - data$NH4_sd[i], data$NH4_mean[i], data$NH4_mean[i] + data$NH4_sd[i]
)
)
# Añadir los datos temporales al dataframe expandido
data_expanded <- rbind(data_expanded, temp)
}
# Mostrar el dataframe expandido
print(data_expanded)
data_expanded$Fecha = NULL
# Ordenar el dataframe expandido por la columna "Variable"
data_expanded <- arrange(data_expanded, Psuelo)
# Reorganizar las columnas para que "Variable" sea la primera
data_expanded <- select(data_expanded, Psuelo, everything())
# Mostrar el dataframe resultante
print(data_expanded)
# Asegurarse de que los factores estén correctamente definidos
data_expanded$Intensidad_Pastoreo <- as.factor(data_expanded$Intensidad_Pastoreo)
data_expanded$Psuelo <- as.factor(data_expanded$Psuelo)
# Anova para DBCA
res.aov <- aov(Valor ~ Intensidad_Pastoreo + Psuelo, data = data_expanded)
summary(res.aov)
# Si hay normalidad en nuestros datos
aov_residuals = residuals(res.aov)
shapiro.test(aov_residuals)
# QQ-plot para verificar normalidad
qqPlot(aov_residuals, main = "QQ-Plot de Residuos")
bartlett.test(Valor ~ Intensidad_Pastoreo, data = data_expanded)
bartlett.test(Valor ~ Psuelo, data = data_expanded)
# If the package remotes is not installed run first:
install.packages("remotes")
remotes::install_github("chrisschuerz/SWATrunR")
library(SWATrunR)
setwd("D:/Proyectos_GitHub/piura_river/data")
library(SWATrunR)
# The path where the SWAT demo project will be written
demo_path <- 'D:/Proyectos_GitHub/piura_river/data'
# Loading a SWAT+ demo project
path_plus <- load_demo(dataset = 'project',
path = demo_path,
version = 'plus')
# Loading a SWAT2012 demo project
path_2012 <- load_demo(dataset = 'project',
path = demo_path,
version = '2012')
q_obs <- load_demo(dataset = 'observation')
q_obs
plot(q_obs, type = 'l')
q_sim_plus <- run_swatplus(project_path = path_plus,
output = define_output(file = 'channel_sd_day',
variable = 'flo_out',
unit = 1))
q_sim_plus
plot(q_sim_plus, type = 'l')
# Prepare the SWAT+ simulation output
q_plus <- q_sim_plus$simulation$flo_out %>%
rename(q_plus = run_1) # Rename the output to q_plus
library(dplyr)
library(lubridate)
library(ggplot2)
library(tidyr)
# Prepare the SWAT+ simulation output
q_plus <- q_sim_plus$simulation$flo_out %>%
rename(q_plus = run_1) # Rename the output to q_plus
# Prepare the table for plotting
q_plot <- q_obs %>%
rename(q_obs = discharge) %>% # Rename the discharge columnt to q_obs
filter(year(date) %in% 2003:2012) %>% # Filter for years between 2003 and 2012
left_join(., q_plus, by = 'date') %>% # Join with the q_plus table by date
left_join(., q_2012, by = 'date') %>% # Join with the q_plus table by date
pivot_longer(., cols = -date, names_to = 'variable', values_to = 'discharge') # Make a long table for plotting
# Prepare the table for plotting
q_plot <- q_obs %>%
rename(q_obs = discharge) %>% # Rename the discharge columnt to q_obs
filter(year(date) %in% 2003:2012) %>% # Filter for years between 2003 and 2012
left_join(., q_plus, by = 'date') %>% # Join with the q_plus table by date
pivot_longer(., cols = -date, names_to = 'variable', values_to = 'discharge') # Make a long table for plotting
q_plot
ggplot(data = q_plot) +
geom_line(aes(x = date, y = discharge, col = variable, lty = variable)) +
scale_color_manual(values = c('tomato3', 'black', 'steelblue3')) +
scale_linetype_manual(values = c('dotted', 'solid', 'dashed')) +
theme_bw()
path_plus
